This is the weekly CEO update from [DoltHub](https://www.dolthub.com/). I'm Tim, the CEO of DoltHub. 

I'm going to be thankful instead because 'tis the season. I quit Snapchat on Dec. 1, 2017, almost 5 years ago. I left Snapchat on Friday and started this company on Monday. By Thursday, I was like "I'm not sure I want to do this right now" and quit my own start up 4 days in. About 6 months later [Aaron](https://www.dolthub.com/team/aaron) and [Brian](https://www.dolthub.com/team/brian) said "Hey Tim, if you're going to do this , we'll do this with you." Now, we built something cool and useful and I'm having a great time doing it. I'm thankful for Aaron and Brian and all the cofounders out there. They don't even read these so I don't need to be bashful here.

### Data Quality Control Opus

Since it is Thanksgiving week, I wrote [a blog targeting the "data quality control"]() search term. I think it turned out really well. It covers the evolution of a data stack at a software company, a model to think about data quality, and tools like OpenRefine, DBT, Great Expectations, Terminus, and Dolt. It' over 4,000 words but I think it's worth it.

[![Data Quality Control](../images/data-quality-control-tools.png)]()

### Dolt Import Performance

We've been [tracking import performance since July](https://www.dolthub.com/blog/2022-07-22-import-benchmarking/). Our original pass at import showed us 10X slower than MySQL. This tracked with the 8X slower we were than MySQL in our `sysbench` tests so we just accepted the result and committed to return to import performance once we had [the new format](https://www.dolthub.com/blog/2022-08-12-new-format-migraiton/).

Surprisingly, the new format didn't do much to change that number. So [we did a deeper dive](https://www.dolthub.com/blog/2022-11-21-import-perf/). What we found is that for most table types we were ~2X slower than MySQL. We had two big problems: blob types (ie. `JSON`, `TEXT`, `LONGTEXT`) and unbatched inserts. The old tests used blob types! 

So, we got a positive surprise and [optimized blob import](https://github.com/dolthub/dolt/pull/4825). We also wrote [a SQL converter to batch up inserts](https://github.com/max-hoffman/insert-batcher) people can use before they import into Dolt.

### Cozy Data

[Zach](https://www.dolthub.com/team/zach) was back at it again with his meme-filled, Reddit owning writing style, this time about a term he is trying to coin ["cozy data"](https://www.dolthub.com/blog/2022-11-18-cozy-data/). Cozy data lives in a log cabin and is special, unlike all that big data that lives in warehouses. SPOILER ALERT: Dolt is the log cabin here. Give it a read. Zach's blogs are always fun.

Until next week. As always, just reply to this email if you want to chat.

--Tim
